import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import yfinance as yf
from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense
from keras.callbacks import EarlyStopping
from sklearn.preprocessing import MinMaxScaler

# Set the GPU to use for training (if available)
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

# Download and preprocess the data
df = yf.download("AAPL", start="2021-01-01", end="2021-12-31")
df["Date"] = pd.to_datetime(df.Date, format="%Y-%m-%d")
df.index = df['Date']
data = df.sort_index(ascending=True, axis=0)
new_dataset = pd.DataFrame(index=range(0, len(df)), columns=['Date', 'Close'])
new_dataset['Date'] = data['Date'].values
new_dataset['Close'] = data['Close'].values
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(new_dataset[['Close']])

# Prepare the training and validation data
train_data = scaled_data[:5000, :]
valid_data = scaled_data[5000:, :]
x_train_data, y_train_data = [], []
for i in range(60, len(train_data)):
    x_train_data.append(train_data[i-60:i, 0])
    y_train_data.append(train_data[i, 0])
x_train_data, y_train_data = np.array(x_train_data), np.array(y_train_data)
x_train_data = np.reshape(x_train_data, (x_train_data.shape[0], x_train_data.shape[1], 1))

# Define the LSTM model
lstm_model = Sequential()
lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train_data.shape[1], 1)))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(units=50))
lstm_model.add(Dropout(0.2))
lstm_model.add(Dense(1))

# Compile and train the LSTM model
lstm_model.compile(loss='mean_squared_error', optimizer='adam')
early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)
history = lstm_model.fit(x_train_data, y_train_data, epochs=100, batch_size=32, verbose=2, validation_split=0.2, callbacks=[early_stopping])

# Prepare the test data and make predictions
inputs_data = scaled_data[len(new_dataset) - len(valid_data) - 60:, :]
inputs_data = np.reshape(inputs_data, (1, inputs_data.shape[0], inputs_data.shape[1]))
predicted_closing_price = lstm_model.predict(inputs_data)
predicted_closing_price = scaler.inverse_transform(predicted_closing_price.reshape(-1, 1))

# Plot the results
train_data = new_dataset[:5000]
valid_data = new_dataset[5000:]
valid_data['Predictions'] = predicted_closing_price
plt.plot(train_data['Close'])
plt.plot(valid_data[['Close', '

#
#
#
#
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.pylab import rcParams
import yfinance as yf
from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense
from sklearn.preprocessing import MinMaxScaler
from keras.callbacks import EarlyStopping

rcParams['figure.figsize'] = 20, 10
df = yf.download("AAPL", start="2021-01-01", end="2021-12-31")
df["Date"] = pd.to_datetime(df.Date, format="%Y-%m-%d")
df.index = df['Date']

plt.figure(figsize=(16, 8))
plt.plot(df["Close"], label='Close Price history')
plt.show()

data = df.sort_index(ascending=True, axis=0)
new_dataset = pd.DataFrame(index=range(0, len(df)), columns=['Date', 'Close'])
for i in range(0, len(data)):
    new_dataset.iloc[i, new_dataset.columns.get_loc('Date')] = data.iloc[i, data.columns.get_loc('Date')]
    new_dataset.iloc[i, new_dataset.columns.get_loc('Close')] = data.iloc[i, data.columns.get_loc('Close')]

scaler = MinMaxScaler(feature_range=(0, 1))
final_dataset = new_dataset.values

train_data = final_dataset[0:5000, :]
valid_data = final_dataset[5000:, :]

scaled_data = scaler.fit_transform(final_dataset)
x_train_data, y_train_data = [], []
for i in range(60, len(train_data)):
    x_train_data.append(scaled_data[i-60:i, 0])
    y_train_data.append(scaled_data[i, 0])

x_train_data, y_train_data = np.array(x_train_data), np.array(y_train_data)
x_train_data = np.reshape(x_train_data, (x_train_data.shape[0], x_train_data.shape[1], 1))

np.random.seed(42)
lstm_model = Sequential()
lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train_data.shape[1], 1)))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(units=50))
lstm_model.add(Dense(1))

lstm_model.compile(loss='mean_squared_error', optimizer='adam')
early_stop = EarlyStopping(monitor='val_loss', patience=10)

history = lstm_model.fit(x_train_data, y_train_data, epochs=100, batch_size=64, verbose=2,
                          validation_split=0.1, callbacks=[early_stop])

inputs_data = new_dataset[len(new_dataset)-len(valid_data)-60:].values
inputs_data = inputs_data

#
#
#
#
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import yfinance as yf
from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense
from sklearn.preprocessing import StandardScaler

# Download data from Yahoo Finance
df = yf.download("AAPL", start="2021-01-01", end="2021-12-31")

# Preprocessing
df["Date"] = pd.to_datetime(df.Date, format="%Y-%m-%d")
df.index = df['Date']
data = df.sort_index(ascending=True, axis=0)
new_dataset = pd.DataFrame(index=range(0, len(df)), columns=['Date', 'Close'])
for i in range(0, len(data)):
    new_dataset["Date"][i] = data['Date'][i]
    new_dataset["Close"][i] = data["Close"][i]

# Split data into train and validation sets
train_data = new_dataset[:5000]
valid_data = new_dataset[5000:]

# Scale the data
scaler = StandardScaler()
scaled_data = scaler.fit_transform(new_dataset[['Close']])

# Create training data
x_train_data, y_train_data = [], []
for i in range(60, len(train_data)):
    x_train_data.append(scaled_data[i-60:i, 0])
    y_train_data.append(scaled_data[i, 0])

x_train_data, y_train_data = np.array(x_train_data), np.array(y_train_data)
x_train_data = np.reshape(x_train_data, (x_train_data.shape[0], x_train_data.shape[1], 1))

# Create and compile the LSTM model
lstm_model = Sequential()
lstm_model.add(LSTM(units=128, return_sequences=True, input_shape=(x_train_data.shape[1], 1)))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(units=128))
lstm_model.add(Dense(units=1))
lstm_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])

# Train the model
history = lstm_model.fit(x_train_data, y_train_data, epochs=50, batch_size=32, verbose=2)

# Create testing data
inputs_data = new_dataset[len(new_dataset)-len(valid_data)-60:][['Close']].values
inputs_data = scaler.transform(inputs_data)
X_test = []
for i in range(60, inputs_data.shape[0]):
    X_test.append(inputs_data[i-60:i, 0])
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[



#
#
#
#
#colum search in the data frame